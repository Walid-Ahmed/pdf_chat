{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Packages"
      ],
      "metadata": {
        "id": "JfbdyWwR07YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget #python package to download files from internet\n",
        "#langchain a software development framework designed to simplify the creation of applications using large language models\n",
        "!pip install langchain\n",
        "!pip install faiss-cpu\n",
        "#tiktoken is a fast BPE tokeniser for use with OpenAI's models\n",
        "!pip install tiktoken \n",
        "#PyPDF2 is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files\n",
        "!pip install PyPDF2\n",
        "#we will use wget to download our pdf file\n",
        "!pip install wget\n",
        "# to work with openAI\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "qH1rUMERzKoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "IFvnRFtF1Vtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
        "import wget"
      ],
      "metadata": {
        "id": "FdkgU8jUzNLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set your OpenAI key"
      ],
      "metadata": {
        "id": "wxVy9FAy1QjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set your Open-AI key\n",
        "#key=\"you_openAI_kEY\"\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = key"
      ],
      "metadata": {
        "id": "bb9czgYUCT8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlorSbccWEDa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download your pdf file"
      ],
      "metadata": {
        "id": "hbgVSNY01eLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://arxiv.org/pdf/2010.11929\"\n",
        "fileName=wget.download(url)\n"
      ],
      "metadata": {
        "id": "CrZob_u754YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read, split and econde text from pdf"
      ],
      "metadata": {
        "id": "SjotKzw81sBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from the file and put them into a variable called pdf_text\n",
        "reader = PdfReader(fileName)\n",
        "pdf_text = ''\n",
        "for page in (reader.pages):\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        pdf_text += text"
      ],
      "metadata": {
        "id": "2VXlucKiW7bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text"
      ],
      "metadata": {
        "id": "Gy3UwHGAZa0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our text splitter\n",
        "text_splitter = CharacterTextSplitter(        \n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000, #thousand charctere\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n"
      ],
      "metadata": {
        "id": "VdXzkpf9XAfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply splitting\n",
        "text_chunks = text_splitter.split_text(pdf_text)"
      ],
      "metadata": {
        "id": "MA4xYsfHGyo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "id": "zY_ZHQGB0CGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[20]"
      ],
      "metadata": {
        "id": "vBZf2LAgz8u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "TcZUsQVyXBPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert text to embeddings\n",
        "pdf_embeddings = FAISS.from_texts(text_chunks, embeddings)"
      ],
      "metadata": {
        "id": "9C8py6wQXE5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "wpQ2VnBvXI2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "_L_Ywm-iXLhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start chatting with the pdf"
      ],
      "metadata": {
        "id": "FwThlzZR0yA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the title of the article?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "print(len(docs))\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "RiSJHGgrQkjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who are the authors of the article?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "3mtAth2jXNKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How was the model accuracy?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "EzNcvjRJXSZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what was the the training dataset?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "Nhx-kpvAXUl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is this model different from other models?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "kIg91Z0YXXCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the conclousion of the paper?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "qLynnMo0cj8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How old is the first author?\"\n",
        "docs = pdf_embeddings.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "P8p41aa2Ew-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Credit: \n",
        "\n",
        "ChatGPT for YOUR OWN PDF files with LangChain \n",
        "https://www.youtube.com/watch?v=TLf90ipMzfE&t=726s"
      ],
      "metadata": {
        "id": "vC2PpuscWm1v"
      }
    }
  ]
}